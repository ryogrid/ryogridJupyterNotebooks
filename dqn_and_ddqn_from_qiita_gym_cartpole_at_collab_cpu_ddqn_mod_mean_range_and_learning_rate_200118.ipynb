{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn_and_ddqn_from_qiita_gym_cartpole_at_collab_cpu_ddqn_mod_mean_range_and_learning_rate_200118.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNzyA1pRt15Kg8Uyk/VExM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryogrid/ryogridJupyterNotebooks/blob/master/dqn_and_ddqn_from_qiita_gym_cartpole_at_collab_cpu_ddqn_mod_mean_range_and_learning_rate_200118.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWnKUAbLAXmF",
        "colab_type": "text"
      },
      "source": [
        "https://qiita.com/sugulu/items/bc7c70e6658f204f85f9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81VK6pAQAN0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa6a9ea5-3fc5-4c62-96f0-e1f56d04be90"
      },
      "source": [
        "# coding:utf-8\n",
        "# [0]必要なライブラリのインポート\n",
        "import gym  # 倒立振子(cartpole)の実行環境\n",
        "import numpy as np\n",
        "import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from collections import deque\n",
        "from gym import wrappers  # gymの画像保存\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# [1]損失関数の定義\n",
        "# 損失関数にhuber関数を使用します 参考https://github.com/jaara/AI-blog/blob/master/CartPole-DQN.py\n",
        "def huberloss(y_true, y_pred):\n",
        "    err = y_true - y_pred\n",
        "    cond = K.abs(err) < 1.0\n",
        "    L2 = 0.5 * K.square(err)\n",
        "    L1 = (K.abs(err) - 0.5)\n",
        "    loss = tf.where(cond, L2, L1)  # Keras does not cover where function in tensorflow :-(\n",
        "    return K.mean(loss)\n",
        "\n",
        "\n",
        "# [2]Q関数をディープラーニングのネットワークをクラスとして定義\n",
        "class QNetwork:\n",
        "    def __init__(self, learning_rate=0.01, state_size=4, action_size=2, hidden_size=10):\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Dense(hidden_size, activation='relu', input_dim=state_size))\n",
        "        self.model.add(Dense(hidden_size, activation='relu'))\n",
        "        self.model.add(Dense(action_size, activation='linear'))\n",
        "        self.optimizer = Adam(lr=learning_rate)  # 誤差を減らす学習方法はAdam\n",
        "        # self.model.compile(loss='mse', optimizer=self.optimizer)\n",
        "        self.model.compile(loss=huberloss, optimizer=self.optimizer)\n",
        "\n",
        "    # 重みの学習\n",
        "    def replay(self, memory, batch_size, gamma, targetQN):\n",
        "        inputs = np.zeros((batch_size, 4))\n",
        "        targets = np.zeros((batch_size, 2))\n",
        "        mini_batch = memory.sample(batch_size)\n",
        "\n",
        "        for i, (state_b, action_b, reward_b, next_state_b) in enumerate(mini_batch):\n",
        "            inputs[i:i + 1] = state_b\n",
        "            target = reward_b\n",
        "\n",
        "            if not (next_state_b == np.zeros(state_b.shape)).all(axis=1):\n",
        "                # 価値計算（DDQNにも対応できるように、行動決定のQネットワークと価値観数のQネットワークは分離）\n",
        "                retmainQs = self.model.predict(next_state_b)[0]\n",
        "                next_action = np.argmax(retmainQs)  # 最大の報酬を返す行動を選択する\n",
        "                target = reward_b + gamma * targetQN.model.predict(next_state_b)[0][next_action]\n",
        "\n",
        "            targets[i] = self.model.predict(state_b)    # Qネットワークの出力\n",
        "            targets[i][action_b] = target               # 教師信号\n",
        "\n",
        "        # shiglayさんよりアドバイスいただき、for文の外へ修正しました\n",
        "        self.model.fit(inputs, targets, epochs=1, verbose=0)  # epochsは訓練データの反復回数、verbose=0は表示なしの設定\n",
        "\n",
        "\n",
        "# [3]Experience ReplayとFixed Target Q-Networkを実現するメモリクラス\n",
        "class Memory:\n",
        "    def __init__(self, max_size=1000):\n",
        "        self.buffer = deque(maxlen=max_size)\n",
        "\n",
        "    def add(self, experience):\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        idx = np.random.choice(np.arange(len(self.buffer)), size=batch_size, replace=False)\n",
        "        return [self.buffer[ii] for ii in idx]\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "\n",
        "# [4]カートの状態に応じて、行動を決定するクラス\n",
        "# アドバイスいただき、引数にtargetQNを使用していたのをmainQNに修正しました\n",
        "class Actor:\n",
        "    def get_action(self, state, episode, mainQN):   # [C]ｔ＋１での行動を返す\n",
        "        # 徐々に最適行動のみをとる、ε-greedy法\n",
        "        epsilon = 0.001 + 0.9 / (1.0+episode)\n",
        "\n",
        "        if epsilon <= np.random.uniform(0, 1):\n",
        "            retTargetQs = mainQN.model.predict(state)[0]\n",
        "            action = np.argmax(retTargetQs)  # 最大の報酬を返す行動を選択する\n",
        "\n",
        "        else:\n",
        "            action = np.random.choice([0, 1])  # ランダムに行動する\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "# [5] メイン関数開始----------------------------------------------------\n",
        "# [5.1] 初期設定--------------------------------------------------------\n",
        "DQN_MODE = 0    # 1がDQN、0がDDQNです\n",
        "LENDER_MODE = 0 # 0は学習後も描画なし、1は学習終了後に描画する\n",
        "\n",
        "env = gym.make('CartPole-v0')\n",
        "num_episodes = 1000  # 総試行回数\n",
        "max_number_of_steps = 200  # 1試行のstep数\n",
        "goal_average_reward = 195  # この報酬を超えると学習終了\n",
        "num_consecutive_iterations = 10  # 学習完了評価の平均計算を行う試行回数\n",
        "total_reward_vec = np.zeros(num_consecutive_iterations)  # 各試行の報酬を格納\n",
        "gamma = 0.99    # 割引係数\n",
        "islearned = 0  # 学習が終わったフラグ\n",
        "isrender = 0  # 描画フラグ\n",
        "# ---\n",
        "hidden_size = 16               # Q-networkの隠れ層のニューロンの数\n",
        "learning_rate = 0.0001 #0.00001         # Q-networkの学習係数\n",
        "memory_size = 10000            # バッファーメモリの大きさ\n",
        "batch_size = 32                # Q-networkを更新するバッチの大記載\n",
        "\n",
        "# [5.2]Qネットワークとメモリ、Actorの生成--------------------------------------------------------\n",
        "mainQN = QNetwork(hidden_size=hidden_size, learning_rate=learning_rate)     # メインのQネットワーク\n",
        "targetQN = QNetwork(hidden_size=hidden_size, learning_rate=learning_rate)   # 価値を計算するQネットワーク\n",
        "# plot_model(mainQN.model, to_file='Qnetwork.png', show_shapes=True)        # Qネットワークの可視化\n",
        "memory = Memory(max_size=memory_size)\n",
        "actor = Actor()\n",
        "\n",
        "# [5.3]メインルーチン--------------------------------------------------------\n",
        "for episode in range(num_episodes):  # 試行数分繰り返す\n",
        "    env.reset()  # cartPoleの環境初期化\n",
        "    state, reward, done, _ = env.step(env.action_space.sample())  # 1step目は適当な行動をとる\n",
        "    state = np.reshape(state, [1, 4])   # list型のstateを、1行4列の行列に変換\n",
        "    episode_reward = 0\n",
        "\n",
        "\n",
        "    # 2018.05.16\n",
        "    # skanmeraさんより間違いを修正いただきました\n",
        "    # targetQN = mainQN   # 行動決定と価値計算のQネットワークをおなじにする\n",
        "    # ↓\n",
        "    targetQN.model.set_weights(mainQN.model.get_weights())\n",
        "\n",
        "    for t in range(max_number_of_steps + 1):  # 1試行のループ\n",
        "        if (islearned == 1) and LENDER_MODE:  # 学習終了したらcartPoleを描画する\n",
        "            env.render()\n",
        "            time.sleep(0.1)\n",
        "            print(state[0, 0])  # カートのx位置を出力するならコメントはずす\n",
        "\n",
        "        action = actor.get_action(state, episode, mainQN)   # 時刻tでの行動を決定する\n",
        "        next_state, reward, done, info = env.step(action)   # 行動a_tの実行による、s_{t+1}, _R{t}を計算する\n",
        "        next_state = np.reshape(next_state, [1, 4])     # list型のstateを、1行4列の行列に変換\n",
        "\n",
        "        # 報酬を設定し、与える\n",
        "        if done:\n",
        "            next_state = np.zeros(state.shape)  # 次の状態s_{t+1}はない\n",
        "            if t < 195:\n",
        "                reward = -1  # 報酬クリッピング、報酬は1, 0, -1に固定\n",
        "            else:\n",
        "                reward = 1  # 立ったまま195step超えて終了時は報酬\n",
        "        else:\n",
        "            reward = 0  # 各ステップで立ってたら報酬追加（はじめからrewardに1が入っているが、明示的に表す）\n",
        "\n",
        "        episode_reward += 1 # reward  # 合計報酬を更新\n",
        "\n",
        "        memory.add((state, action, reward, next_state))     # メモリの更新する\n",
        "        state = next_state  # 状態更新\n",
        "\n",
        "\n",
        "        # Qネットワークの重みを学習・更新する replay\n",
        "        if (memory.len() > batch_size) and not islearned:\n",
        "            mainQN.replay(memory, batch_size, gamma, targetQN)\n",
        "\n",
        "        if DQN_MODE:\n",
        "        # 2018.06.12\n",
        "        # shiglayさんさんより間違いを修正いただきました\n",
        "        # targetQN = mainQN   # 行動決定と価値計算のQネットワークをおなじにする\n",
        "        # ↓\n",
        "            targetQN.model.set_weights(mainQN.model.get_weights())\n",
        "\n",
        "        # 1施行終了時の処理\n",
        "        if done:\n",
        "            total_reward_vec = np.hstack((total_reward_vec[1:], episode_reward))  # 報酬を記録\n",
        "            print('%d Episode finished after %f time steps / episode_reward %f / mean of last 20 episode %f' % (episode, t + 1, episode_reward, total_reward_vec[0:19].mean()))\n",
        "            break\n",
        "\n",
        "    # 複数施行の平均報酬で終了を判断\n",
        "    if total_reward_vec[0:19].mean() >= goal_average_reward:\n",
        "        print('Episode %d train agent successfuly!' % episode)\n",
        "        islearned = 1\n",
        "        if isrender == 0:   # 学習済みフラグを更新\n",
        "            isrender = 1\n",
        "\n",
        "            # env = wrappers.Monitor(env, './movie/cartpoleDDQN')  # 動画保存する場合\n",
        "            # 10エピソードだけでどんな挙動になるのか見たかったら、以下のコメントを外す\n",
        "            # if episode>10:\n",
        "            #    if isrender == 0:\n",
        "            #        env = wrappers.Monitor(env, './movie/cartpole-experiment-1') #動画保存する場合\n",
        "            #        isrender = 1\n",
        "            #    islearned=1;"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-1-709dff113de7>:21: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "0 Episode finished after 17.000000 time steps / episode_reward 17.000000 / mean of last 20 episode 1.700000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "1 Episode finished after 28.000000 time steps / episode_reward 28.000000 / mean of last 20 episode 4.500000\n",
            "2 Episode finished after 7.000000 time steps / episode_reward 7.000000 / mean of last 20 episode 5.200000\n",
            "3 Episode finished after 14.000000 time steps / episode_reward 14.000000 / mean of last 20 episode 6.600000\n",
            "4 Episode finished after 10.000000 time steps / episode_reward 10.000000 / mean of last 20 episode 7.600000\n",
            "5 Episode finished after 8.000000 time steps / episode_reward 8.000000 / mean of last 20 episode 8.400000\n",
            "6 Episode finished after 9.000000 time steps / episode_reward 9.000000 / mean of last 20 episode 9.300000\n",
            "7 Episode finished after 10.000000 time steps / episode_reward 10.000000 / mean of last 20 episode 10.300000\n",
            "8 Episode finished after 7.000000 time steps / episode_reward 7.000000 / mean of last 20 episode 11.000000\n",
            "9 Episode finished after 40.000000 time steps / episode_reward 40.000000 / mean of last 20 episode 15.000000\n",
            "10 Episode finished after 8.000000 time steps / episode_reward 8.000000 / mean of last 20 episode 14.100000\n",
            "11 Episode finished after 56.000000 time steps / episode_reward 56.000000 / mean of last 20 episode 16.900000\n",
            "12 Episode finished after 27.000000 time steps / episode_reward 27.000000 / mean of last 20 episode 18.900000\n",
            "13 Episode finished after 24.000000 time steps / episode_reward 24.000000 / mean of last 20 episode 19.900000\n",
            "14 Episode finished after 40.000000 time steps / episode_reward 40.000000 / mean of last 20 episode 22.900000\n",
            "15 Episode finished after 31.000000 time steps / episode_reward 31.000000 / mean of last 20 episode 25.200000\n",
            "16 Episode finished after 35.000000 time steps / episode_reward 35.000000 / mean of last 20 episode 27.800000\n",
            "17 Episode finished after 33.000000 time steps / episode_reward 33.000000 / mean of last 20 episode 30.100000\n",
            "18 Episode finished after 42.000000 time steps / episode_reward 42.000000 / mean of last 20 episode 33.600000\n",
            "19 Episode finished after 86.000000 time steps / episode_reward 86.000000 / mean of last 20 episode 38.200000\n",
            "20 Episode finished after 84.000000 time steps / episode_reward 84.000000 / mean of last 20 episode 45.800000\n",
            "21 Episode finished after 42.000000 time steps / episode_reward 42.000000 / mean of last 20 episode 44.400000\n",
            "22 Episode finished after 56.000000 time steps / episode_reward 56.000000 / mean of last 20 episode 47.300000\n",
            "23 Episode finished after 68.000000 time steps / episode_reward 68.000000 / mean of last 20 episode 51.700000\n",
            "24 Episode finished after 73.000000 time steps / episode_reward 73.000000 / mean of last 20 episode 55.000000\n",
            "25 Episode finished after 95.000000 time steps / episode_reward 95.000000 / mean of last 20 episode 61.400000\n",
            "26 Episode finished after 87.000000 time steps / episode_reward 87.000000 / mean of last 20 episode 66.600000\n",
            "27 Episode finished after 55.000000 time steps / episode_reward 55.000000 / mean of last 20 episode 68.800000\n",
            "28 Episode finished after 62.000000 time steps / episode_reward 62.000000 / mean of last 20 episode 70.800000\n",
            "29 Episode finished after 70.000000 time steps / episode_reward 70.000000 / mean of last 20 episode 69.200000\n",
            "30 Episode finished after 50.000000 time steps / episode_reward 50.000000 / mean of last 20 episode 65.800000\n",
            "31 Episode finished after 79.000000 time steps / episode_reward 79.000000 / mean of last 20 episode 69.500000\n",
            "32 Episode finished after 59.000000 time steps / episode_reward 59.000000 / mean of last 20 episode 69.800000\n",
            "33 Episode finished after 47.000000 time steps / episode_reward 47.000000 / mean of last 20 episode 67.700000\n",
            "34 Episode finished after 50.000000 time steps / episode_reward 50.000000 / mean of last 20 episode 65.400000\n",
            "35 Episode finished after 46.000000 time steps / episode_reward 46.000000 / mean of last 20 episode 60.500000\n",
            "36 Episode finished after 102.000000 time steps / episode_reward 102.000000 / mean of last 20 episode 62.000000\n",
            "37 Episode finished after 95.000000 time steps / episode_reward 95.000000 / mean of last 20 episode 66.000000\n",
            "38 Episode finished after 118.000000 time steps / episode_reward 118.000000 / mean of last 20 episode 71.600000\n",
            "39 Episode finished after 68.000000 time steps / episode_reward 68.000000 / mean of last 20 episode 71.400000\n",
            "40 Episode finished after 81.000000 time steps / episode_reward 81.000000 / mean of last 20 episode 74.500000\n",
            "41 Episode finished after 55.000000 time steps / episode_reward 55.000000 / mean of last 20 episode 72.100000\n",
            "42 Episode finished after 70.000000 time steps / episode_reward 70.000000 / mean of last 20 episode 73.200000\n",
            "43 Episode finished after 101.000000 time steps / episode_reward 101.000000 / mean of last 20 episode 78.600000\n",
            "44 Episode finished after 135.000000 time steps / episode_reward 135.000000 / mean of last 20 episode 87.100000\n",
            "45 Episode finished after 105.000000 time steps / episode_reward 105.000000 / mean of last 20 episode 93.000000\n",
            "46 Episode finished after 70.000000 time steps / episode_reward 70.000000 / mean of last 20 episode 89.800000\n",
            "47 Episode finished after 120.000000 time steps / episode_reward 120.000000 / mean of last 20 episode 92.300000\n",
            "48 Episode finished after 196.000000 time steps / episode_reward 196.000000 / mean of last 20 episode 100.100000\n",
            "49 Episode finished after 139.000000 time steps / episode_reward 139.000000 / mean of last 20 episode 107.200000\n",
            "50 Episode finished after 81.000000 time steps / episode_reward 81.000000 / mean of last 20 episode 107.200000\n",
            "51 Episode finished after 96.000000 time steps / episode_reward 96.000000 / mean of last 20 episode 111.300000\n",
            "52 Episode finished after 92.000000 time steps / episode_reward 92.000000 / mean of last 20 episode 113.500000\n",
            "53 Episode finished after 140.000000 time steps / episode_reward 140.000000 / mean of last 20 episode 117.400000\n",
            "54 Episode finished after 80.000000 time steps / episode_reward 80.000000 / mean of last 20 episode 111.900000\n",
            "55 Episode finished after 66.000000 time steps / episode_reward 66.000000 / mean of last 20 episode 108.000000\n",
            "56 Episode finished after 90.000000 time steps / episode_reward 90.000000 / mean of last 20 episode 110.000000\n",
            "57 Episode finished after 77.000000 time steps / episode_reward 77.000000 / mean of last 20 episode 105.700000\n",
            "58 Episode finished after 70.000000 time steps / episode_reward 70.000000 / mean of last 20 episode 93.100000\n",
            "59 Episode finished after 197.000000 time steps / episode_reward 197.000000 / mean of last 20 episode 98.900000\n",
            "60 Episode finished after 62.000000 time steps / episode_reward 62.000000 / mean of last 20 episode 97.000000\n",
            "61 Episode finished after 70.000000 time steps / episode_reward 70.000000 / mean of last 20 episode 94.400000\n",
            "62 Episode finished after 54.000000 time steps / episode_reward 54.000000 / mean of last 20 episode 90.600000\n",
            "63 Episode finished after 87.000000 time steps / episode_reward 87.000000 / mean of last 20 episode 85.300000\n",
            "64 Episode finished after 73.000000 time steps / episode_reward 73.000000 / mean of last 20 episode 84.600000\n",
            "65 Episode finished after 62.000000 time steps / episode_reward 62.000000 / mean of last 20 episode 84.200000\n",
            "66 Episode finished after 51.000000 time steps / episode_reward 51.000000 / mean of last 20 episode 80.300000\n",
            "67 Episode finished after 55.000000 time steps / episode_reward 55.000000 / mean of last 20 episode 78.100000\n",
            "68 Episode finished after 71.000000 time steps / episode_reward 71.000000 / mean of last 20 episode 78.200000\n",
            "69 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 78.400000\n",
            "70 Episode finished after 68.000000 time steps / episode_reward 68.000000 / mean of last 20 episode 79.000000\n",
            "71 Episode finished after 62.000000 time steps / episode_reward 62.000000 / mean of last 20 episode 78.200000\n",
            "72 Episode finished after 88.000000 time steps / episode_reward 88.000000 / mean of last 20 episode 81.600000\n",
            "73 Episode finished after 81.000000 time steps / episode_reward 81.000000 / mean of last 20 episode 81.000000\n",
            "74 Episode finished after 114.000000 time steps / episode_reward 114.000000 / mean of last 20 episode 85.100000\n",
            "75 Episode finished after 90.000000 time steps / episode_reward 90.000000 / mean of last 20 episode 87.900000\n",
            "76 Episode finished after 78.000000 time steps / episode_reward 78.000000 / mean of last 20 episode 90.600000\n",
            "77 Episode finished after 133.000000 time steps / episode_reward 133.000000 / mean of last 20 episode 98.400000\n",
            "78 Episode finished after 84.000000 time steps / episode_reward 84.000000 / mean of last 20 episode 99.700000\n",
            "79 Episode finished after 85.000000 time steps / episode_reward 85.000000 / mean of last 20 episode 88.300000\n",
            "80 Episode finished after 87.000000 time steps / episode_reward 87.000000 / mean of last 20 episode 90.200000\n",
            "81 Episode finished after 73.000000 time steps / episode_reward 73.000000 / mean of last 20 episode 91.300000\n",
            "82 Episode finished after 78.000000 time steps / episode_reward 78.000000 / mean of last 20 episode 90.300000\n",
            "83 Episode finished after 61.000000 time steps / episode_reward 61.000000 / mean of last 20 episode 88.300000\n",
            "84 Episode finished after 86.000000 time steps / episode_reward 86.000000 / mean of last 20 episode 85.500000\n",
            "85 Episode finished after 76.000000 time steps / episode_reward 76.000000 / mean of last 20 episode 84.100000\n",
            "86 Episode finished after 82.000000 time steps / episode_reward 82.000000 / mean of last 20 episode 84.500000\n",
            "87 Episode finished after 110.000000 time steps / episode_reward 110.000000 / mean of last 20 episode 82.200000\n",
            "88 Episode finished after 105.000000 time steps / episode_reward 105.000000 / mean of last 20 episode 84.300000\n",
            "89 Episode finished after 89.000000 time steps / episode_reward 89.000000 / mean of last 20 episode 84.700000\n",
            "90 Episode finished after 73.000000 time steps / episode_reward 73.000000 / mean of last 20 episode 83.300000\n",
            "91 Episode finished after 69.000000 time steps / episode_reward 69.000000 / mean of last 20 episode 82.900000\n",
            "92 Episode finished after 134.000000 time steps / episode_reward 134.000000 / mean of last 20 episode 88.500000\n",
            "93 Episode finished after 61.000000 time steps / episode_reward 61.000000 / mean of last 20 episode 88.500000\n",
            "94 Episode finished after 65.000000 time steps / episode_reward 65.000000 / mean of last 20 episode 86.400000\n",
            "95 Episode finished after 84.000000 time steps / episode_reward 84.000000 / mean of last 20 episode 87.200000\n",
            "96 Episode finished after 164.000000 time steps / episode_reward 164.000000 / mean of last 20 episode 95.400000\n",
            "97 Episode finished after 66.000000 time steps / episode_reward 66.000000 / mean of last 20 episode 91.000000\n",
            "98 Episode finished after 120.000000 time steps / episode_reward 120.000000 / mean of last 20 episode 92.500000\n",
            "99 Episode finished after 55.000000 time steps / episode_reward 55.000000 / mean of last 20 episode 89.100000\n",
            "100 Episode finished after 58.000000 time steps / episode_reward 58.000000 / mean of last 20 episode 87.600000\n",
            "101 Episode finished after 71.000000 time steps / episode_reward 71.000000 / mean of last 20 episode 87.800000\n",
            "102 Episode finished after 64.000000 time steps / episode_reward 64.000000 / mean of last 20 episode 80.800000\n",
            "103 Episode finished after 50.000000 time steps / episode_reward 50.000000 / mean of last 20 episode 79.700000\n",
            "104 Episode finished after 107.000000 time steps / episode_reward 107.000000 / mean of last 20 episode 83.900000\n",
            "105 Episode finished after 102.000000 time steps / episode_reward 102.000000 / mean of last 20 episode 85.700000\n",
            "106 Episode finished after 93.000000 time steps / episode_reward 93.000000 / mean of last 20 episode 78.600000\n",
            "107 Episode finished after 69.000000 time steps / episode_reward 69.000000 / mean of last 20 episode 78.900000\n",
            "108 Episode finished after 62.000000 time steps / episode_reward 62.000000 / mean of last 20 episode 73.100000\n",
            "109 Episode finished after 120.000000 time steps / episode_reward 120.000000 / mean of last 20 episode 79.600000\n",
            "110 Episode finished after 59.000000 time steps / episode_reward 59.000000 / mean of last 20 episode 79.700000\n",
            "111 Episode finished after 73.000000 time steps / episode_reward 73.000000 / mean of last 20 episode 79.900000\n",
            "112 Episode finished after 67.000000 time steps / episode_reward 67.000000 / mean of last 20 episode 80.200000\n",
            "113 Episode finished after 146.000000 time steps / episode_reward 146.000000 / mean of last 20 episode 89.800000\n",
            "114 Episode finished after 82.000000 time steps / episode_reward 82.000000 / mean of last 20 episode 87.300000\n",
            "115 Episode finished after 136.000000 time steps / episode_reward 136.000000 / mean of last 20 episode 90.700000\n",
            "116 Episode finished after 82.000000 time steps / episode_reward 82.000000 / mean of last 20 episode 89.600000\n",
            "117 Episode finished after 85.000000 time steps / episode_reward 85.000000 / mean of last 20 episode 91.200000\n",
            "118 Episode finished after 64.000000 time steps / episode_reward 64.000000 / mean of last 20 episode 91.400000\n",
            "119 Episode finished after 137.000000 time steps / episode_reward 137.000000 / mean of last 20 episode 93.100000\n",
            "120 Episode finished after 144.000000 time steps / episode_reward 144.000000 / mean of last 20 episode 101.600000\n",
            "121 Episode finished after 68.000000 time steps / episode_reward 68.000000 / mean of last 20 episode 101.100000\n",
            "122 Episode finished after 147.000000 time steps / episode_reward 147.000000 / mean of last 20 episode 109.100000\n",
            "123 Episode finished after 130.000000 time steps / episode_reward 130.000000 / mean of last 20 episode 107.500000\n",
            "124 Episode finished after 81.000000 time steps / episode_reward 81.000000 / mean of last 20 episode 107.400000\n",
            "125 Episode finished after 126.000000 time steps / episode_reward 126.000000 / mean of last 20 episode 106.400000\n",
            "126 Episode finished after 156.000000 time steps / episode_reward 156.000000 / mean of last 20 episode 113.800000\n",
            "127 Episode finished after 81.000000 time steps / episode_reward 81.000000 / mean of last 20 episode 113.400000\n",
            "128 Episode finished after 68.000000 time steps / episode_reward 68.000000 / mean of last 20 episode 113.800000\n",
            "129 Episode finished after 180.000000 time steps / episode_reward 180.000000 / mean of last 20 episode 118.100000\n",
            "130 Episode finished after 118.000000 time steps / episode_reward 118.000000 / mean of last 20 episode 115.500000\n",
            "131 Episode finished after 66.000000 time steps / episode_reward 66.000000 / mean of last 20 episode 115.300000\n",
            "132 Episode finished after 137.000000 time steps / episode_reward 137.000000 / mean of last 20 episode 114.300000\n",
            "133 Episode finished after 74.000000 time steps / episode_reward 74.000000 / mean of last 20 episode 108.700000\n",
            "134 Episode finished after 132.000000 time steps / episode_reward 132.000000 / mean of last 20 episode 113.800000\n",
            "135 Episode finished after 110.000000 time steps / episode_reward 110.000000 / mean of last 20 episode 112.200000\n",
            "136 Episode finished after 71.000000 time steps / episode_reward 71.000000 / mean of last 20 episode 103.700000\n",
            "137 Episode finished after 80.000000 time steps / episode_reward 80.000000 / mean of last 20 episode 103.600000\n",
            "138 Episode finished after 76.000000 time steps / episode_reward 76.000000 / mean of last 20 episode 104.400000\n",
            "139 Episode finished after 128.000000 time steps / episode_reward 128.000000 / mean of last 20 episode 99.200000\n",
            "140 Episode finished after 155.000000 time steps / episode_reward 155.000000 / mean of last 20 episode 102.900000\n",
            "141 Episode finished after 76.000000 time steps / episode_reward 76.000000 / mean of last 20 episode 103.900000\n",
            "142 Episode finished after 155.000000 time steps / episode_reward 155.000000 / mean of last 20 episode 105.700000\n",
            "143 Episode finished after 107.000000 time steps / episode_reward 107.000000 / mean of last 20 episode 109.000000\n",
            "144 Episode finished after 99.000000 time steps / episode_reward 99.000000 / mean of last 20 episode 105.700000\n",
            "145 Episode finished after 132.000000 time steps / episode_reward 132.000000 / mean of last 20 episode 107.900000\n",
            "146 Episode finished after 110.000000 time steps / episode_reward 110.000000 / mean of last 20 episode 111.800000\n",
            "147 Episode finished after 135.000000 time steps / episode_reward 135.000000 / mean of last 20 episode 117.300000\n",
            "148 Episode finished after 78.000000 time steps / episode_reward 78.000000 / mean of last 20 episode 117.500000\n",
            "149 Episode finished after 125.000000 time steps / episode_reward 125.000000 / mean of last 20 episode 117.200000\n",
            "150 Episode finished after 71.000000 time steps / episode_reward 71.000000 / mean of last 20 episode 108.800000\n",
            "151 Episode finished after 74.000000 time steps / episode_reward 74.000000 / mean of last 20 episode 108.600000\n",
            "152 Episode finished after 78.000000 time steps / episode_reward 78.000000 / mean of last 20 episode 100.900000\n",
            "153 Episode finished after 111.000000 time steps / episode_reward 111.000000 / mean of last 20 episode 101.300000\n",
            "154 Episode finished after 81.000000 time steps / episode_reward 81.000000 / mean of last 20 episode 99.500000\n",
            "155 Episode finished after 75.000000 time steps / episode_reward 75.000000 / mean of last 20 episode 93.800000\n",
            "156 Episode finished after 89.000000 time steps / episode_reward 89.000000 / mean of last 20 episode 91.700000\n",
            "157 Episode finished after 98.000000 time steps / episode_reward 98.000000 / mean of last 20 episode 88.000000\n",
            "158 Episode finished after 101.000000 time steps / episode_reward 101.000000 / mean of last 20 episode 90.300000\n",
            "159 Episode finished after 96.000000 time steps / episode_reward 96.000000 / mean of last 20 episode 87.400000\n",
            "160 Episode finished after 83.000000 time steps / episode_reward 83.000000 / mean of last 20 episode 88.600000\n",
            "161 Episode finished after 79.000000 time steps / episode_reward 79.000000 / mean of last 20 episode 89.100000\n",
            "162 Episode finished after 164.000000 time steps / episode_reward 164.000000 / mean of last 20 episode 97.700000\n",
            "163 Episode finished after 75.000000 time steps / episode_reward 75.000000 / mean of last 20 episode 94.100000\n",
            "164 Episode finished after 174.000000 time steps / episode_reward 174.000000 / mean of last 20 episode 103.400000\n",
            "165 Episode finished after 104.000000 time steps / episode_reward 104.000000 / mean of last 20 episode 106.300000\n",
            "166 Episode finished after 80.000000 time steps / episode_reward 80.000000 / mean of last 20 episode 105.400000\n",
            "167 Episode finished after 88.000000 time steps / episode_reward 88.000000 / mean of last 20 episode 104.400000\n",
            "168 Episode finished after 63.000000 time steps / episode_reward 63.000000 / mean of last 20 episode 100.600000\n",
            "169 Episode finished after 79.000000 time steps / episode_reward 79.000000 / mean of last 20 episode 98.900000\n",
            "170 Episode finished after 71.000000 time steps / episode_reward 71.000000 / mean of last 20 episode 97.700000\n",
            "171 Episode finished after 106.000000 time steps / episode_reward 106.000000 / mean of last 20 episode 100.400000\n",
            "172 Episode finished after 103.000000 time steps / episode_reward 103.000000 / mean of last 20 episode 94.300000\n",
            "173 Episode finished after 140.000000 time steps / episode_reward 140.000000 / mean of last 20 episode 100.800000\n",
            "174 Episode finished after 83.000000 time steps / episode_reward 83.000000 / mean of last 20 episode 91.700000\n",
            "175 Episode finished after 81.000000 time steps / episode_reward 81.000000 / mean of last 20 episode 89.400000\n",
            "176 Episode finished after 90.000000 time steps / episode_reward 90.000000 / mean of last 20 episode 90.400000\n",
            "177 Episode finished after 109.000000 time steps / episode_reward 109.000000 / mean of last 20 episode 92.500000\n",
            "178 Episode finished after 71.000000 time steps / episode_reward 71.000000 / mean of last 20 episode 93.300000\n",
            "179 Episode finished after 72.000000 time steps / episode_reward 72.000000 / mean of last 20 episode 92.600000\n",
            "180 Episode finished after 120.000000 time steps / episode_reward 120.000000 / mean of last 20 episode 97.500000\n",
            "181 Episode finished after 89.000000 time steps / episode_reward 89.000000 / mean of last 20 episode 95.800000\n",
            "182 Episode finished after 74.000000 time steps / episode_reward 74.000000 / mean of last 20 episode 92.900000\n",
            "183 Episode finished after 76.000000 time steps / episode_reward 76.000000 / mean of last 20 episode 86.500000\n",
            "184 Episode finished after 122.000000 time steps / episode_reward 122.000000 / mean of last 20 episode 90.400000\n",
            "185 Episode finished after 84.000000 time steps / episode_reward 84.000000 / mean of last 20 episode 90.700000\n",
            "186 Episode finished after 100.000000 time steps / episode_reward 100.000000 / mean of last 20 episode 91.700000\n",
            "187 Episode finished after 157.000000 time steps / episode_reward 157.000000 / mean of last 20 episode 96.500000\n",
            "188 Episode finished after 77.000000 time steps / episode_reward 77.000000 / mean of last 20 episode 97.100000\n",
            "189 Episode finished after 94.000000 time steps / episode_reward 94.000000 / mean of last 20 episode 99.300000\n",
            "190 Episode finished after 109.000000 time steps / episode_reward 109.000000 / mean of last 20 episode 98.200000\n",
            "191 Episode finished after 68.000000 time steps / episode_reward 68.000000 / mean of last 20 episode 96.100000\n",
            "192 Episode finished after 160.000000 time steps / episode_reward 160.000000 / mean of last 20 episode 104.700000\n",
            "193 Episode finished after 87.000000 time steps / episode_reward 87.000000 / mean of last 20 episode 105.800000\n",
            "194 Episode finished after 95.000000 time steps / episode_reward 95.000000 / mean of last 20 episode 103.100000\n",
            "195 Episode finished after 77.000000 time steps / episode_reward 77.000000 / mean of last 20 episode 102.400000\n",
            "196 Episode finished after 137.000000 time steps / episode_reward 137.000000 / mean of last 20 episode 106.100000\n",
            "197 Episode finished after 87.000000 time steps / episode_reward 87.000000 / mean of last 20 episode 99.100000\n",
            "198 Episode finished after 78.000000 time steps / episode_reward 78.000000 / mean of last 20 episode 99.200000\n",
            "199 Episode finished after 75.000000 time steps / episode_reward 75.000000 / mean of last 20 episode 97.300000\n",
            "200 Episode finished after 69.000000 time steps / episode_reward 69.000000 / mean of last 20 episode 93.300000\n",
            "201 Episode finished after 85.000000 time steps / episode_reward 85.000000 / mean of last 20 episode 95.000000\n",
            "202 Episode finished after 81.000000 time steps / episode_reward 81.000000 / mean of last 20 episode 87.100000\n",
            "203 Episode finished after 172.000000 time steps / episode_reward 172.000000 / mean of last 20 episode 95.600000\n",
            "204 Episode finished after 102.000000 time steps / episode_reward 102.000000 / mean of last 20 episode 96.300000\n",
            "205 Episode finished after 145.000000 time steps / episode_reward 145.000000 / mean of last 20 episode 103.100000\n",
            "206 Episode finished after 111.000000 time steps / episode_reward 111.000000 / mean of last 20 episode 100.500000\n",
            "207 Episode finished after 96.000000 time steps / episode_reward 96.000000 / mean of last 20 episode 101.400000\n",
            "208 Episode finished after 110.000000 time steps / episode_reward 110.000000 / mean of last 20 episode 104.600000\n",
            "209 Episode finished after 115.000000 time steps / episode_reward 115.000000 / mean of last 20 episode 108.600000\n",
            "210 Episode finished after 155.000000 time steps / episode_reward 155.000000 / mean of last 20 episode 117.200000\n",
            "211 Episode finished after 51.000000 time steps / episode_reward 51.000000 / mean of last 20 episode 113.800000\n",
            "212 Episode finished after 161.000000 time steps / episode_reward 161.000000 / mean of last 20 episode 121.800000\n",
            "213 Episode finished after 146.000000 time steps / episode_reward 146.000000 / mean of last 20 episode 119.200000\n",
            "214 Episode finished after 124.000000 time steps / episode_reward 124.000000 / mean of last 20 episode 121.400000\n",
            "215 Episode finished after 95.000000 time steps / episode_reward 95.000000 / mean of last 20 episode 116.400000\n",
            "216 Episode finished after 85.000000 time steps / episode_reward 85.000000 / mean of last 20 episode 113.800000\n",
            "217 Episode finished after 144.000000 time steps / episode_reward 144.000000 / mean of last 20 episode 118.600000\n",
            "218 Episode finished after 163.000000 time steps / episode_reward 163.000000 / mean of last 20 episode 123.900000\n",
            "219 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 132.300000\n",
            "220 Episode finished after 179.000000 time steps / episode_reward 179.000000 / mean of last 20 episode 134.700000\n",
            "221 Episode finished after 172.000000 time steps / episode_reward 172.000000 / mean of last 20 episode 146.800000\n",
            "222 Episode finished after 140.000000 time steps / episode_reward 140.000000 / mean of last 20 episode 144.700000\n",
            "223 Episode finished after 123.000000 time steps / episode_reward 123.000000 / mean of last 20 episode 142.400000\n",
            "224 Episode finished after 154.000000 time steps / episode_reward 154.000000 / mean of last 20 episode 145.400000\n",
            "225 Episode finished after 130.000000 time steps / episode_reward 130.000000 / mean of last 20 episode 148.900000\n",
            "226 Episode finished after 161.000000 time steps / episode_reward 161.000000 / mean of last 20 episode 156.500000\n",
            "227 Episode finished after 141.000000 time steps / episode_reward 141.000000 / mean of last 20 episode 156.200000\n",
            "228 Episode finished after 119.000000 time steps / episode_reward 119.000000 / mean of last 20 episode 151.800000\n",
            "229 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 151.800000\n",
            "230 Episode finished after 123.000000 time steps / episode_reward 123.000000 / mean of last 20 episode 146.200000\n",
            "231 Episode finished after 160.000000 time steps / episode_reward 160.000000 / mean of last 20 episode 145.000000\n",
            "232 Episode finished after 153.000000 time steps / episode_reward 153.000000 / mean of last 20 episode 146.300000\n",
            "233 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 153.900000\n",
            "234 Episode finished after 150.000000 time steps / episode_reward 150.000000 / mean of last 20 episode 153.500000\n",
            "235 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 160.400000\n",
            "236 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 164.200000\n",
            "237 Episode finished after 197.000000 time steps / episode_reward 197.000000 / mean of last 20 episode 169.800000\n",
            "238 Episode finished after 154.000000 time steps / episode_reward 154.000000 / mean of last 20 episode 173.300000\n",
            "239 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 173.300000\n",
            "240 Episode finished after 170.000000 time steps / episode_reward 170.000000 / mean of last 20 episode 178.000000\n",
            "241 Episode finished after 162.000000 time steps / episode_reward 162.000000 / mean of last 20 episode 178.200000\n",
            "242 Episode finished after 197.000000 time steps / episode_reward 197.000000 / mean of last 20 episode 182.600000\n",
            "243 Episode finished after 173.000000 time steps / episode_reward 173.000000 / mean of last 20 episode 180.000000\n",
            "244 Episode finished after 151.000000 time steps / episode_reward 151.000000 / mean of last 20 episode 180.100000\n",
            "245 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 180.100000\n",
            "246 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 180.100000\n",
            "247 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 180.300000\n",
            "248 Episode finished after 198.000000 time steps / episode_reward 198.000000 / mean of last 20 episode 184.700000\n",
            "249 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 184.700000\n",
            "250 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 187.600000\n",
            "251 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 191.300000\n",
            "252 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 191.500000\n",
            "253 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 194.100000\n",
            "254 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 254 train agent successfuly!\n",
            "255 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 255 train agent successfuly!\n",
            "256 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 256 train agent successfuly!\n",
            "257 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 257 train agent successfuly!\n",
            "258 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 258 train agent successfuly!\n",
            "259 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 259 train agent successfuly!\n",
            "260 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 260 train agent successfuly!\n",
            "261 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 261 train agent successfuly!\n",
            "262 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 262 train agent successfuly!\n",
            "263 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 263 train agent successfuly!\n",
            "264 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 264 train agent successfuly!\n",
            "265 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 265 train agent successfuly!\n",
            "266 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 266 train agent successfuly!\n",
            "267 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 267 train agent successfuly!\n",
            "268 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 268 train agent successfuly!\n",
            "269 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 269 train agent successfuly!\n",
            "270 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 270 train agent successfuly!\n",
            "271 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 271 train agent successfuly!\n",
            "272 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 272 train agent successfuly!\n",
            "273 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 273 train agent successfuly!\n",
            "274 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 274 train agent successfuly!\n",
            "275 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 275 train agent successfuly!\n",
            "276 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 276 train agent successfuly!\n",
            "277 Episode finished after 193.000000 time steps / episode_reward 193.000000 / mean of last 20 episode 198.400000\n",
            "Episode 277 train agent successfuly!\n",
            "278 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.400000\n",
            "Episode 278 train agent successfuly!\n",
            "279 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.400000\n",
            "Episode 279 train agent successfuly!\n",
            "280 Episode finished after 171.000000 time steps / episode_reward 171.000000 / mean of last 20 episode 195.600000\n",
            "Episode 280 train agent successfuly!\n",
            "281 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.600000\n",
            "Episode 281 train agent successfuly!\n",
            "282 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.600000\n",
            "Episode 282 train agent successfuly!\n",
            "283 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.600000\n",
            "Episode 283 train agent successfuly!\n",
            "284 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.600000\n",
            "Episode 284 train agent successfuly!\n",
            "285 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.600000\n",
            "Episode 285 train agent successfuly!\n",
            "286 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.600000\n",
            "Episode 286 train agent successfuly!\n",
            "287 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.200000\n",
            "Episode 287 train agent successfuly!\n",
            "288 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.200000\n",
            "Episode 288 train agent successfuly!\n",
            "289 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.200000\n",
            "Episode 289 train agent successfuly!\n",
            "290 Episode finished after 198.000000 time steps / episode_reward 198.000000 / mean of last 20 episode 198.900000\n",
            "Episode 290 train agent successfuly!\n",
            "291 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 291 train agent successfuly!\n",
            "292 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 292 train agent successfuly!\n",
            "293 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 293 train agent successfuly!\n",
            "294 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 294 train agent successfuly!\n",
            "295 Episode finished after 171.000000 time steps / episode_reward 171.000000 / mean of last 20 episode 196.100000\n",
            "Episode 295 train agent successfuly!\n",
            "296 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.100000\n",
            "Episode 296 train agent successfuly!\n",
            "297 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.100000\n",
            "Episode 297 train agent successfuly!\n",
            "298 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.100000\n",
            "Episode 298 train agent successfuly!\n",
            "299 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.100000\n",
            "Episode 299 train agent successfuly!\n",
            "300 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.200000\n",
            "Episode 300 train agent successfuly!\n",
            "301 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.200000\n",
            "Episode 301 train agent successfuly!\n",
            "302 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.200000\n",
            "Episode 302 train agent successfuly!\n",
            "303 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.200000\n",
            "Episode 303 train agent successfuly!\n",
            "304 Episode finished after 170.000000 time steps / episode_reward 170.000000 / mean of last 20 episode 193.300000\n",
            "305 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.100000\n",
            "Episode 305 train agent successfuly!\n",
            "306 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.100000\n",
            "Episode 306 train agent successfuly!\n",
            "307 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.100000\n",
            "Episode 307 train agent successfuly!\n",
            "308 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.100000\n",
            "Episode 308 train agent successfuly!\n",
            "309 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.100000\n",
            "Episode 309 train agent successfuly!\n",
            "310 Episode finished after 195.000000 time steps / episode_reward 195.000000 / mean of last 20 episode 195.700000\n",
            "Episode 310 train agent successfuly!\n",
            "311 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.700000\n",
            "Episode 311 train agent successfuly!\n",
            "312 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.700000\n",
            "Episode 312 train agent successfuly!\n",
            "313 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.700000\n",
            "Episode 313 train agent successfuly!\n",
            "314 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.600000\n",
            "Episode 314 train agent successfuly!\n",
            "315 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.600000\n",
            "Episode 315 train agent successfuly!\n",
            "316 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.600000\n",
            "Episode 316 train agent successfuly!\n",
            "317 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.600000\n",
            "Episode 317 train agent successfuly!\n",
            "318 Episode finished after 192.000000 time steps / episode_reward 192.000000 / mean of last 20 episode 197.900000\n",
            "Episode 318 train agent successfuly!\n",
            "319 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.900000\n",
            "Episode 319 train agent successfuly!\n",
            "320 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 320 train agent successfuly!\n",
            "321 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 321 train agent successfuly!\n",
            "322 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 322 train agent successfuly!\n",
            "323 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 323 train agent successfuly!\n",
            "324 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 324 train agent successfuly!\n",
            "325 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 325 train agent successfuly!\n",
            "326 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 326 train agent successfuly!\n",
            "327 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 327 train agent successfuly!\n",
            "328 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 328 train agent successfuly!\n",
            "329 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 329 train agent successfuly!\n",
            "330 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 330 train agent successfuly!\n",
            "331 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 331 train agent successfuly!\n",
            "332 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 332 train agent successfuly!\n",
            "333 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 333 train agent successfuly!\n",
            "334 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 334 train agent successfuly!\n",
            "335 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 335 train agent successfuly!\n",
            "336 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 336 train agent successfuly!\n",
            "337 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 337 train agent successfuly!\n",
            "338 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 338 train agent successfuly!\n",
            "339 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 339 train agent successfuly!\n",
            "340 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 340 train agent successfuly!\n",
            "341 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 341 train agent successfuly!\n",
            "342 Episode finished after 191.000000 time steps / episode_reward 191.000000 / mean of last 20 episode 198.200000\n",
            "Episode 342 train agent successfuly!\n",
            "343 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 343 train agent successfuly!\n",
            "344 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 344 train agent successfuly!\n",
            "345 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 345 train agent successfuly!\n",
            "346 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 346 train agent successfuly!\n",
            "347 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 347 train agent successfuly!\n",
            "348 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 348 train agent successfuly!\n",
            "349 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 349 train agent successfuly!\n",
            "350 Episode finished after 197.000000 time steps / episode_reward 197.000000 / mean of last 20 episode 198.000000\n",
            "Episode 350 train agent successfuly!\n",
            "351 Episode finished after 146.000000 time steps / episode_reward 146.000000 / mean of last 20 episode 192.700000\n",
            "352 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.500000\n",
            "353 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.500000\n",
            "354 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.500000\n",
            "355 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.500000\n",
            "356 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.500000\n",
            "357 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.500000\n",
            "358 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.500000\n",
            "359 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.500000\n",
            "360 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.700000\n",
            "361 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 361 train agent successfuly!\n",
            "362 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 362 train agent successfuly!\n",
            "363 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 363 train agent successfuly!\n",
            "364 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 364 train agent successfuly!\n",
            "365 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 365 train agent successfuly!\n",
            "366 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 366 train agent successfuly!\n",
            "367 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 367 train agent successfuly!\n",
            "368 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 368 train agent successfuly!\n",
            "369 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 369 train agent successfuly!\n",
            "370 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 370 train agent successfuly!\n",
            "371 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 371 train agent successfuly!\n",
            "372 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 372 train agent successfuly!\n",
            "373 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 373 train agent successfuly!\n",
            "374 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 374 train agent successfuly!\n",
            "375 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 375 train agent successfuly!\n",
            "376 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 376 train agent successfuly!\n",
            "377 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 377 train agent successfuly!\n",
            "378 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 378 train agent successfuly!\n",
            "379 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 379 train agent successfuly!\n",
            "380 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 380 train agent successfuly!\n",
            "381 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 381 train agent successfuly!\n",
            "382 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 382 train agent successfuly!\n",
            "383 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 383 train agent successfuly!\n",
            "384 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 384 train agent successfuly!\n",
            "385 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 385 train agent successfuly!\n",
            "386 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 386 train agent successfuly!\n",
            "387 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 387 train agent successfuly!\n",
            "388 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 388 train agent successfuly!\n",
            "389 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 389 train agent successfuly!\n",
            "390 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 390 train agent successfuly!\n",
            "391 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 391 train agent successfuly!\n",
            "392 Episode finished after 191.000000 time steps / episode_reward 191.000000 / mean of last 20 episode 198.200000\n",
            "Episode 392 train agent successfuly!\n",
            "393 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 393 train agent successfuly!\n",
            "394 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 394 train agent successfuly!\n",
            "395 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 395 train agent successfuly!\n",
            "396 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 396 train agent successfuly!\n",
            "397 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 397 train agent successfuly!\n",
            "398 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 398 train agent successfuly!\n",
            "399 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 399 train agent successfuly!\n",
            "400 Episode finished after 197.000000 time steps / episode_reward 197.000000 / mean of last 20 episode 198.000000\n",
            "Episode 400 train agent successfuly!\n",
            "401 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.000000\n",
            "Episode 401 train agent successfuly!\n",
            "402 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.800000\n",
            "Episode 402 train agent successfuly!\n",
            "403 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.800000\n",
            "Episode 403 train agent successfuly!\n",
            "404 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.800000\n",
            "Episode 404 train agent successfuly!\n",
            "405 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.800000\n",
            "Episode 405 train agent successfuly!\n",
            "406 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.800000\n",
            "Episode 406 train agent successfuly!\n",
            "407 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.800000\n",
            "Episode 407 train agent successfuly!\n",
            "408 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.800000\n",
            "Episode 408 train agent successfuly!\n",
            "409 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.800000\n",
            "Episode 409 train agent successfuly!\n",
            "410 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 410 train agent successfuly!\n",
            "411 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 411 train agent successfuly!\n",
            "412 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 412 train agent successfuly!\n",
            "413 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 413 train agent successfuly!\n",
            "414 Episode finished after 174.000000 time steps / episode_reward 174.000000 / mean of last 20 episode 196.500000\n",
            "Episode 414 train agent successfuly!\n",
            "415 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 415 train agent successfuly!\n",
            "416 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 416 train agent successfuly!\n",
            "417 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 417 train agent successfuly!\n",
            "418 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 418 train agent successfuly!\n",
            "419 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 419 train agent successfuly!\n",
            "420 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 420 train agent successfuly!\n",
            "421 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 421 train agent successfuly!\n",
            "422 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 422 train agent successfuly!\n",
            "423 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 423 train agent successfuly!\n",
            "424 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 424 train agent successfuly!\n",
            "425 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 425 train agent successfuly!\n",
            "426 Episode finished after 184.000000 time steps / episode_reward 184.000000 / mean of last 20 episode 197.500000\n",
            "Episode 426 train agent successfuly!\n",
            "427 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 427 train agent successfuly!\n",
            "428 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 428 train agent successfuly!\n",
            "429 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 429 train agent successfuly!\n",
            "430 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 430 train agent successfuly!\n",
            "431 Episode finished after 175.000000 time steps / episode_reward 175.000000 / mean of last 20 episode 195.100000\n",
            "Episode 431 train agent successfuly!\n",
            "432 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.100000\n",
            "Episode 432 train agent successfuly!\n",
            "433 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.100000\n",
            "Episode 433 train agent successfuly!\n",
            "434 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.100000\n",
            "Episode 434 train agent successfuly!\n",
            "435 Episode finished after 198.000000 time steps / episode_reward 198.000000 / mean of last 20 episode 195.000000\n",
            "Episode 435 train agent successfuly!\n",
            "436 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 436 train agent successfuly!\n",
            "437 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 437 train agent successfuly!\n",
            "438 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 438 train agent successfuly!\n",
            "439 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 439 train agent successfuly!\n",
            "440 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.500000\n",
            "Episode 440 train agent successfuly!\n",
            "441 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 441 train agent successfuly!\n",
            "442 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.900000\n",
            "Episode 442 train agent successfuly!\n",
            "443 Episode finished after 192.000000 time steps / episode_reward 192.000000 / mean of last 20 episode 198.200000\n",
            "Episode 443 train agent successfuly!\n",
            "444 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.200000\n",
            "Episode 444 train agent successfuly!\n",
            "445 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 445 train agent successfuly!\n",
            "446 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 446 train agent successfuly!\n",
            "447 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 447 train agent successfuly!\n",
            "448 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 448 train agent successfuly!\n",
            "449 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 449 train agent successfuly!\n",
            "450 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 450 train agent successfuly!\n",
            "451 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 451 train agent successfuly!\n",
            "452 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.300000\n",
            "Episode 452 train agent successfuly!\n",
            "453 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 453 train agent successfuly!\n",
            "454 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 454 train agent successfuly!\n",
            "455 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 455 train agent successfuly!\n",
            "456 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 456 train agent successfuly!\n",
            "457 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 457 train agent successfuly!\n",
            "458 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 458 train agent successfuly!\n",
            "459 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 459 train agent successfuly!\n",
            "460 Episode finished after 196.000000 time steps / episode_reward 196.000000 / mean of last 20 episode 198.700000\n",
            "Episode 460 train agent successfuly!\n",
            "461 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 461 train agent successfuly!\n",
            "462 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 462 train agent successfuly!\n",
            "463 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 463 train agent successfuly!\n",
            "464 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 464 train agent successfuly!\n",
            "465 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 465 train agent successfuly!\n",
            "466 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 466 train agent successfuly!\n",
            "467 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 467 train agent successfuly!\n",
            "468 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 468 train agent successfuly!\n",
            "469 Episode finished after 168.000000 time steps / episode_reward 168.000000 / mean of last 20 episode 195.600000\n",
            "Episode 469 train agent successfuly!\n",
            "470 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.900000\n",
            "Episode 470 train agent successfuly!\n",
            "471 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.900000\n",
            "Episode 471 train agent successfuly!\n",
            "472 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.900000\n",
            "Episode 472 train agent successfuly!\n",
            "473 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.900000\n",
            "Episode 473 train agent successfuly!\n",
            "474 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.900000\n",
            "Episode 474 train agent successfuly!\n",
            "475 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.900000\n",
            "Episode 475 train agent successfuly!\n",
            "476 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.900000\n",
            "Episode 476 train agent successfuly!\n",
            "477 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.900000\n",
            "Episode 477 train agent successfuly!\n",
            "478 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.900000\n",
            "Episode 478 train agent successfuly!\n",
            "479 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 479 train agent successfuly!\n",
            "480 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 480 train agent successfuly!\n",
            "481 Episode finished after 190.000000 time steps / episode_reward 190.000000 / mean of last 20 episode 198.100000\n",
            "Episode 481 train agent successfuly!\n",
            "482 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.100000\n",
            "Episode 482 train agent successfuly!\n",
            "483 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.100000\n",
            "Episode 483 train agent successfuly!\n",
            "484 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.100000\n",
            "Episode 484 train agent successfuly!\n",
            "485 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.100000\n",
            "Episode 485 train agent successfuly!\n",
            "486 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.100000\n",
            "Episode 486 train agent successfuly!\n",
            "487 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.100000\n",
            "Episode 487 train agent successfuly!\n",
            "488 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.100000\n",
            "Episode 488 train agent successfuly!\n",
            "489 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.100000\n",
            "Episode 489 train agent successfuly!\n",
            "490 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.100000\n",
            "Episode 490 train agent successfuly!\n",
            "491 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 491 train agent successfuly!\n",
            "492 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 492 train agent successfuly!\n",
            "493 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 493 train agent successfuly!\n",
            "494 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 494 train agent successfuly!\n",
            "495 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 495 train agent successfuly!\n",
            "496 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 496 train agent successfuly!\n",
            "497 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 497 train agent successfuly!\n",
            "498 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 498 train agent successfuly!\n",
            "499 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 499 train agent successfuly!\n",
            "500 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 500 train agent successfuly!\n",
            "501 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 501 train agent successfuly!\n",
            "502 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 502 train agent successfuly!\n",
            "503 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 503 train agent successfuly!\n",
            "504 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 504 train agent successfuly!\n",
            "505 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 505 train agent successfuly!\n",
            "506 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 506 train agent successfuly!\n",
            "507 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 507 train agent successfuly!\n",
            "508 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 508 train agent successfuly!\n",
            "509 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 509 train agent successfuly!\n",
            "510 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 510 train agent successfuly!\n",
            "511 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 511 train agent successfuly!\n",
            "512 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 512 train agent successfuly!\n",
            "513 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 513 train agent successfuly!\n",
            "514 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 514 train agent successfuly!\n",
            "515 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 515 train agent successfuly!\n",
            "516 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 516 train agent successfuly!\n",
            "517 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 517 train agent successfuly!\n",
            "518 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 518 train agent successfuly!\n",
            "519 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 519 train agent successfuly!\n",
            "520 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 520 train agent successfuly!\n",
            "521 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 521 train agent successfuly!\n",
            "522 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 522 train agent successfuly!\n",
            "523 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 523 train agent successfuly!\n",
            "524 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 524 train agent successfuly!\n",
            "525 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 525 train agent successfuly!\n",
            "526 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 526 train agent successfuly!\n",
            "527 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 527 train agent successfuly!\n",
            "528 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 528 train agent successfuly!\n",
            "529 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 529 train agent successfuly!\n",
            "530 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 530 train agent successfuly!\n",
            "531 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 531 train agent successfuly!\n",
            "532 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 532 train agent successfuly!\n",
            "533 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 533 train agent successfuly!\n",
            "534 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 534 train agent successfuly!\n",
            "535 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 535 train agent successfuly!\n",
            "536 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 536 train agent successfuly!\n",
            "537 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 537 train agent successfuly!\n",
            "538 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 538 train agent successfuly!\n",
            "539 Episode finished after 179.000000 time steps / episode_reward 179.000000 / mean of last 20 episode 197.000000\n",
            "Episode 539 train agent successfuly!\n",
            "540 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.000000\n",
            "Episode 540 train agent successfuly!\n",
            "541 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.000000\n",
            "Episode 541 train agent successfuly!\n",
            "542 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.000000\n",
            "Episode 542 train agent successfuly!\n",
            "543 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.000000\n",
            "Episode 543 train agent successfuly!\n",
            "544 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.000000\n",
            "Episode 544 train agent successfuly!\n",
            "545 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.000000\n",
            "Episode 545 train agent successfuly!\n",
            "546 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.000000\n",
            "Episode 546 train agent successfuly!\n",
            "547 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.000000\n",
            "Episode 547 train agent successfuly!\n",
            "548 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.000000\n",
            "Episode 548 train agent successfuly!\n",
            "549 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 549 train agent successfuly!\n",
            "550 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 550 train agent successfuly!\n",
            "551 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 551 train agent successfuly!\n",
            "552 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 552 train agent successfuly!\n",
            "553 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 553 train agent successfuly!\n",
            "554 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 554 train agent successfuly!\n",
            "555 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 555 train agent successfuly!\n",
            "556 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 556 train agent successfuly!\n",
            "557 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 557 train agent successfuly!\n",
            "558 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 558 train agent successfuly!\n",
            "559 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 559 train agent successfuly!\n",
            "560 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 560 train agent successfuly!\n",
            "561 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 561 train agent successfuly!\n",
            "562 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 562 train agent successfuly!\n",
            "563 Episode finished after 197.000000 time steps / episode_reward 197.000000 / mean of last 20 episode 198.800000\n",
            "Episode 563 train agent successfuly!\n",
            "564 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.800000\n",
            "Episode 564 train agent successfuly!\n",
            "565 Episode finished after 180.000000 time steps / episode_reward 180.000000 / mean of last 20 episode 196.900000\n",
            "Episode 565 train agent successfuly!\n",
            "566 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 196.900000\n",
            "Episode 566 train agent successfuly!\n",
            "567 Episode finished after 161.000000 time steps / episode_reward 161.000000 / mean of last 20 episode 193.100000\n",
            "568 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.100000\n",
            "569 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.100000\n",
            "570 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.100000\n",
            "571 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.100000\n",
            "572 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.100000\n",
            "573 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.300000\n",
            "574 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 193.300000\n",
            "575 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.200000\n",
            "Episode 575 train agent successfuly!\n",
            "576 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 195.200000\n",
            "Episode 576 train agent successfuly!\n",
            "577 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 577 train agent successfuly!\n",
            "578 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 578 train agent successfuly!\n",
            "579 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 579 train agent successfuly!\n",
            "580 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 580 train agent successfuly!\n",
            "581 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 581 train agent successfuly!\n",
            "582 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 582 train agent successfuly!\n",
            "583 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 583 train agent successfuly!\n",
            "584 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 584 train agent successfuly!\n",
            "585 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 585 train agent successfuly!\n",
            "586 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 586 train agent successfuly!\n",
            "587 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 587 train agent successfuly!\n",
            "588 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 588 train agent successfuly!\n",
            "589 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 589 train agent successfuly!\n",
            "590 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 590 train agent successfuly!\n",
            "591 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 591 train agent successfuly!\n",
            "592 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 592 train agent successfuly!\n",
            "593 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 593 train agent successfuly!\n",
            "594 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 594 train agent successfuly!\n",
            "595 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 595 train agent successfuly!\n",
            "596 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 596 train agent successfuly!\n",
            "597 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 597 train agent successfuly!\n",
            "598 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 598 train agent successfuly!\n",
            "599 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 599 train agent successfuly!\n",
            "600 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 600 train agent successfuly!\n",
            "601 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 601 train agent successfuly!\n",
            "602 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 602 train agent successfuly!\n",
            "603 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 603 train agent successfuly!\n",
            "604 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 604 train agent successfuly!\n",
            "605 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 605 train agent successfuly!\n",
            "606 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 606 train agent successfuly!\n",
            "607 Episode finished after 186.000000 time steps / episode_reward 186.000000 / mean of last 20 episode 197.700000\n",
            "Episode 607 train agent successfuly!\n",
            "608 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.700000\n",
            "Episode 608 train agent successfuly!\n",
            "609 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.700000\n",
            "Episode 609 train agent successfuly!\n",
            "610 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.700000\n",
            "Episode 610 train agent successfuly!\n",
            "611 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.700000\n",
            "Episode 611 train agent successfuly!\n",
            "612 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.700000\n",
            "Episode 612 train agent successfuly!\n",
            "613 Episode finished after 137.000000 time steps / episode_reward 137.000000 / mean of last 20 episode 191.500000\n",
            "614 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 191.500000\n",
            "615 Episode finished after 196.000000 time steps / episode_reward 196.000000 / mean of last 20 episode 191.200000\n",
            "616 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 191.200000\n",
            "617 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 192.500000\n",
            "618 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 192.500000\n",
            "619 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 192.500000\n",
            "620 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 192.500000\n",
            "621 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 192.500000\n",
            "622 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 192.500000\n",
            "623 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 623 train agent successfuly!\n",
            "624 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 624 train agent successfuly!\n",
            "625 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 625 train agent successfuly!\n",
            "626 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 626 train agent successfuly!\n",
            "627 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 627 train agent successfuly!\n",
            "628 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 628 train agent successfuly!\n",
            "629 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 629 train agent successfuly!\n",
            "630 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 630 train agent successfuly!\n",
            "631 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 631 train agent successfuly!\n",
            "632 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 632 train agent successfuly!\n",
            "633 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 633 train agent successfuly!\n",
            "634 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 634 train agent successfuly!\n",
            "635 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 635 train agent successfuly!\n",
            "636 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 636 train agent successfuly!\n",
            "637 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 637 train agent successfuly!\n",
            "638 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 638 train agent successfuly!\n",
            "639 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 639 train agent successfuly!\n",
            "640 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 640 train agent successfuly!\n",
            "641 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 641 train agent successfuly!\n",
            "642 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 642 train agent successfuly!\n",
            "643 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 643 train agent successfuly!\n",
            "644 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 644 train agent successfuly!\n",
            "645 Episode finished after 184.000000 time steps / episode_reward 184.000000 / mean of last 20 episode 197.500000\n",
            "Episode 645 train agent successfuly!\n",
            "646 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 646 train agent successfuly!\n",
            "647 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 647 train agent successfuly!\n",
            "648 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 648 train agent successfuly!\n",
            "649 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 649 train agent successfuly!\n",
            "650 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 650 train agent successfuly!\n",
            "651 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 651 train agent successfuly!\n",
            "652 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 652 train agent successfuly!\n",
            "653 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 653 train agent successfuly!\n",
            "654 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.500000\n",
            "Episode 654 train agent successfuly!\n",
            "655 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 655 train agent successfuly!\n",
            "656 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 656 train agent successfuly!\n",
            "657 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 657 train agent successfuly!\n",
            "658 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 658 train agent successfuly!\n",
            "659 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 659 train agent successfuly!\n",
            "660 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 660 train agent successfuly!\n",
            "661 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 661 train agent successfuly!\n",
            "662 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 662 train agent successfuly!\n",
            "663 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 663 train agent successfuly!\n",
            "664 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 664 train agent successfuly!\n",
            "665 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 665 train agent successfuly!\n",
            "666 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 666 train agent successfuly!\n",
            "667 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 667 train agent successfuly!\n",
            "668 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 668 train agent successfuly!\n",
            "669 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 669 train agent successfuly!\n",
            "670 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 670 train agent successfuly!\n",
            "671 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 671 train agent successfuly!\n",
            "672 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 672 train agent successfuly!\n",
            "673 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 673 train agent successfuly!\n",
            "674 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 674 train agent successfuly!\n",
            "675 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 675 train agent successfuly!\n",
            "676 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 676 train agent successfuly!\n",
            "677 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 677 train agent successfuly!\n",
            "678 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 678 train agent successfuly!\n",
            "679 Episode finished after 196.000000 time steps / episode_reward 196.000000 / mean of last 20 episode 198.700000\n",
            "Episode 679 train agent successfuly!\n",
            "680 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 680 train agent successfuly!\n",
            "681 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.700000\n",
            "Episode 681 train agent successfuly!\n",
            "682 Episode finished after 197.000000 time steps / episode_reward 197.000000 / mean of last 20 episode 198.500000\n",
            "Episode 682 train agent successfuly!\n",
            "683 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.500000\n",
            "Episode 683 train agent successfuly!\n",
            "684 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 198.500000\n",
            "Episode 684 train agent successfuly!\n",
            "685 Episode finished after 187.000000 time steps / episode_reward 187.000000 / mean of last 20 episode 197.300000\n",
            "Episode 685 train agent successfuly!\n",
            "686 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.300000\n",
            "Episode 686 train agent successfuly!\n",
            "687 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.300000\n",
            "Episode 687 train agent successfuly!\n",
            "688 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.300000\n",
            "Episode 688 train agent successfuly!\n",
            "689 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.600000\n",
            "Episode 689 train agent successfuly!\n",
            "690 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.600000\n",
            "Episode 690 train agent successfuly!\n",
            "691 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.600000\n",
            "Episode 691 train agent successfuly!\n",
            "692 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.800000\n",
            "Episode 692 train agent successfuly!\n",
            "693 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.800000\n",
            "Episode 693 train agent successfuly!\n",
            "694 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 197.800000\n",
            "Episode 694 train agent successfuly!\n",
            "695 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 695 train agent successfuly!\n",
            "696 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 696 train agent successfuly!\n",
            "697 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 697 train agent successfuly!\n",
            "698 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 698 train agent successfuly!\n",
            "699 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 699 train agent successfuly!\n",
            "700 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 700 train agent successfuly!\n",
            "701 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 701 train agent successfuly!\n",
            "702 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 702 train agent successfuly!\n",
            "703 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 703 train agent successfuly!\n",
            "704 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 704 train agent successfuly!\n",
            "705 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 705 train agent successfuly!\n",
            "706 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 706 train agent successfuly!\n",
            "707 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 707 train agent successfuly!\n",
            "708 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 708 train agent successfuly!\n",
            "709 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 709 train agent successfuly!\n",
            "710 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 710 train agent successfuly!\n",
            "711 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 711 train agent successfuly!\n",
            "712 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 712 train agent successfuly!\n",
            "713 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 713 train agent successfuly!\n",
            "714 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 714 train agent successfuly!\n",
            "715 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 715 train agent successfuly!\n",
            "716 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 716 train agent successfuly!\n",
            "717 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 717 train agent successfuly!\n",
            "718 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 718 train agent successfuly!\n",
            "719 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 719 train agent successfuly!\n",
            "720 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 720 train agent successfuly!\n",
            "721 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 721 train agent successfuly!\n",
            "722 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 722 train agent successfuly!\n",
            "723 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 723 train agent successfuly!\n",
            "724 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 724 train agent successfuly!\n",
            "725 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 725 train agent successfuly!\n",
            "726 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 726 train agent successfuly!\n",
            "727 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 727 train agent successfuly!\n",
            "728 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 728 train agent successfuly!\n",
            "729 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 729 train agent successfuly!\n",
            "730 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 730 train agent successfuly!\n",
            "731 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 731 train agent successfuly!\n",
            "732 Episode finished after 199.000000 time steps / episode_reward 199.000000 / mean of last 20 episode 199.000000\n",
            "Episode 732 train agent successfuly!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-709dff113de7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# カートのx位置を出力するならコメントはずす\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmainQN\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 時刻tでの行動を決定する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 行動a_tの実行による、s_{t+1}, _R{t}を計算する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# list型のstateを、1行4列の行列に変換\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-709dff113de7>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state, episode, mainQN)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mretTargetQs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretTargetQs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 最大の報酬を返す行動を選択する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}